{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import pipeline\n",
    "from transformers import RobertaTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "from transformers import AutoTokenizer\n",
    "import logging\n",
    "import time\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\34616\\miniconda3\\envs\\gpu_pluja\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "# Configuración para el uso de la GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Haciendo logging para monitorear errores\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    handlers = [\n",
    "                        logging.StreamHandler(),\n",
    "                    ]\n",
    ")\n",
    "\n",
    "# Cargar el tokenizador y el modelo localmente en la GPU\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model.to(device)  # Mover el modelo a la GPU\n",
    "\n",
    "# Función para dividir el texto en chunks respetando el límite de tokens\n",
    "def chunk_text(text, tokenizer, chunk_size=512):\n",
    "    tokens = tokenizer(text, truncation=True, max_length=chunk_size, return_tensors='pt')\n",
    "    input_ids = tokens.input_ids[0]\n",
    "    for i in range(0, len(input_ids), chunk_size):\n",
    "        chunk_ids = input_ids[i:i + chunk_size]\n",
    "        yield tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
    "\n",
    "# Función para guardar el progreso en CSV\n",
    "def guardar_progreso(df, ruta_guardado):\n",
    "    if not df.empty:\n",
    "        try:\n",
    "            logging.info(\"Guardando el progreso...\")\n",
    "            arch_existe = os.path.isfile(ruta_guardado)\n",
    "            df.to_csv(ruta_guardado, mode='a', header=not arch_existe, index=False)\n",
    "            logging.info(f\"Se han guardado {len(df)} instancias correctamente\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ha habido un error al guardar el progreso: {e}\")\n",
    "            logging.info(f\"{len(df)} instancias no guardadas\")\n",
    "\n",
    "# Función para analizar los sentimientos en el dataframe en chunks\n",
    "def analyze_sentiments_chunked(df, tokenizer, model, chunk_size=512, save_threshold=10000, process_chunk_size=5000):\n",
    "    processed_count = 0\n",
    "    ch_num = 0\n",
    "    # Procesar el dataframe en chunks de `process_chunk_size`\n",
    "    for start in range(0, len(df), process_chunk_size):\n",
    "        ch_num += 1\n",
    "        end = min(start + process_chunk_size, len(df))\n",
    "        chunk_df = df.iloc[start:end]\n",
    "\n",
    "        # defining lists\n",
    "        sentiment_list = []\n",
    "        score_list = []\n",
    "        negative_scores = []\n",
    "        neutral_scores = []\n",
    "        positive_scores = []\n",
    "\n",
    "        logging.info(f\"Analyzing chunk n.{ch_num}\")\n",
    "        print(f\"Procesando chunk-group n.{ch_num}\")\n",
    "        \n",
    "        for idx, text in enumerate(chunk_df['text']):\n",
    "            chunks = list(chunk_text(text, tokenizer, chunk_size=chunk_size))\n",
    "            overall_sentiment = None\n",
    "            max_score = -1  # Inicializar a un valor bajo\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "                \n",
    "                # Realizar la inferencia en la GPU\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    logits = outputs.logits\n",
    "                    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "                    sentiment_score, sentiment_idx = torch.max(probs, dim=-1)\n",
    "                \n",
    "                label = model.config.id2label[sentiment_idx.item()]\n",
    "                \n",
    "                # Si el score es mayor que el máximo actual, actualiza\n",
    "                if sentiment_score.item() > max_score:\n",
    "                    max_score = sentiment_score.item()\n",
    "                    overall_sentiment = label\n",
    "            \n",
    "            sentiment_list.append(overall_sentiment)\n",
    "            score_list.append(max_score)\n",
    "        \n",
    "        # Asignar sentimientos y puntajes al chunk\n",
    "        df.loc[start:end-1, 'sentiment'] = sentiment_list\n",
    "        df.loc[start:end-1, 'score'] = score_list\n",
    "        processed_count += len(chunk_df)\n",
    "        \n",
    "        # Guardar el progreso después de cada `save_threshold` filas\n",
    "        if processed_count >= save_threshold:\n",
    "            guardar_progreso(df.iloc[start:end], ruta_guardado)\n",
    "            processed_count = 0\n",
    "    \n",
    "    # Guardar el progreso final\n",
    "    guardar_progreso(df, ruta_guardado)\n",
    "\n",
    "# Ruta para guardar el archivo de progreso\n",
    "ruta_guardado = r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\roBERTa results\\df_2nda_corrida_3sentiments.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:06:28,693 - INFO - Analyzing chunk n.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:07:33,232 - INFO - Analyzing chunk n.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:08:34,637 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:08:34,672 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:08:34,672 - INFO - Analyzing chunk n.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:09:32,829 - INFO - Analyzing chunk n.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:10:30,940 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:10:30,984 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:10:30,984 - INFO - Analyzing chunk n.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:11:33,683 - INFO - Analyzing chunk n.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:12:35,892 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:12:35,935 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:12:35,937 - INFO - Analyzing chunk n.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:13:39,612 - INFO - Analyzing chunk n.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:14:38,935 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:14:38,981 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:14:38,982 - INFO - Analyzing chunk n.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:15:41,378 - INFO - Analyzing chunk n.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:16:38,735 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:16:38,770 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:16:38,771 - INFO - Analyzing chunk n.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:17:33,101 - INFO - Analyzing chunk n.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:18:28,128 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:18:28,163 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:18:28,164 - INFO - Analyzing chunk n.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:19:23,034 - INFO - Analyzing chunk n.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:20:18,422 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:20:18,463 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:20:18,464 - INFO - Analyzing chunk n.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:21:14,026 - INFO - Analyzing chunk n.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:22:09,274 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:22:09,318 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:22:09,319 - INFO - Analyzing chunk n.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:22:52,593 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:22:53,216 - INFO - Se han guardado 84045 instancias correctamente\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\Bipolar\\df_bipolar_full.csv\")\n",
    "analyze_sentiments_chunked(df, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.4.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>labels</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Media: Nobody knows what kamala is about\\n\\nMe...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.564157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NYT breaking news that Netanyahu has agreed to...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.930298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I was thinking this morning about how freaking...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.433811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I was on a break talking to a 25-year old cowo...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Republican</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.885671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Went to the Kamala rally today in WI and it wa...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.604938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84040</th>\n",
       "      <td>84040</td>\n",
       "      <td>&gt; No, Some Republicans aren’t motivated to vot...</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.482519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84041</th>\n",
       "      <td>84041</td>\n",
       "      <td>That would apply if Trump hadn’t won and lost....</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.593608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84042</th>\n",
       "      <td>84042</td>\n",
       "      <td>How many pardons has trump issued?</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>0.729522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84043</th>\n",
       "      <td>84043</td>\n",
       "      <td>Should post this all over the subs who keep bl...</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.776307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84044</th>\n",
       "      <td>84044</td>\n",
       "      <td>Kamala loves felons. Should be a great debate.</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.591324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84045 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               text  \\\n",
       "0               0  Media: Nobody knows what kamala is about\\n\\nMe...   \n",
       "1               1  NYT breaking news that Netanyahu has agreed to...   \n",
       "2               2  I was thinking this morning about how freaking...   \n",
       "3               3  I was on a break talking to a 25-year old cowo...   \n",
       "4               4  Went to the Kamala rally today in WI and it wa...   \n",
       "...           ...                                                ...   \n",
       "84040       84040  > No, Some Republicans aren’t motivated to vot...   \n",
       "84041       84041  That would apply if Trump hadn’t won and lost....   \n",
       "84042       84042                 How many pardons has trump issued?   \n",
       "84043       84043  Should post this all over the subs who keep bl...   \n",
       "84044       84044     Kamala loves felons. Should be a great debate.   \n",
       "\n",
       "      submission_type   subreddit      labels sentiment     score  \n",
       "0             comment    politics    Democrat   LABEL_1  0.564157  \n",
       "1             comment    politics    Democrat   LABEL_2  0.930298  \n",
       "2             comment    politics    Democrat   LABEL_1  0.433811  \n",
       "3             comment    politics  Republican   LABEL_0  0.885671  \n",
       "4             comment    politics    Democrat   LABEL_2  0.604938  \n",
       "...               ...         ...         ...       ...       ...  \n",
       "84040         comment  Republican  Republican   LABEL_1  0.482519  \n",
       "84041         comment  Republican  Republican   LABEL_1  0.593608  \n",
       "84042         comment  Republican  Republican   LABEL_1  0.729522  \n",
       "84043         comment  Republican    Democrat   LABEL_0  0.776307  \n",
       "84044         comment  Republican    Democrat   LABEL_2  0.591324  \n",
       "\n",
       "[84045 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_corrido = pd.read_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\roBERTa results\\df_primera_corrida.csv\")\n",
    "df_corrido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora pa que funcionen las 3 cosas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\34616\\miniconda3\\envs\\gpu_pluja\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "# Configuración para el uso de la GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Haciendo logging para monitorear errores\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    handlers = [\n",
    "                        logging.StreamHandler(),\n",
    "                    ]\n",
    ")\n",
    "\n",
    "# Cargar el tokenizador y el modelo localmente en la GPU\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model.to(device)  # Mover el modelo a la GPU\n",
    "\n",
    "# Función para dividir el texto en chunks respetando el límite de tokens\n",
    "def chunk_text(text, tokenizer, chunk_size=512):\n",
    "    tokens = tokenizer(text, truncation=True, max_length=chunk_size, return_tensors='pt')\n",
    "    input_ids = tokens.input_ids[0]\n",
    "    for i in range(0, len(input_ids), chunk_size):\n",
    "        chunk_ids = input_ids[i:i + chunk_size]\n",
    "        yield tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
    "\n",
    "# Función para guardar el progreso en CSV\n",
    "def guardar_progreso(df, ruta_guardado):\n",
    "    if not df.empty:\n",
    "        try:\n",
    "            logging.info(\"Guardando el progreso...\")\n",
    "            arch_existe = os.path.isfile(ruta_guardado)\n",
    "            df.to_csv(ruta_guardado, mode='a', header=not arch_existe, index=False)\n",
    "            logging.info(f\"Se han guardado {len(df)} instancias correctamente\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ha habido un error al guardar el progreso: {e}\")\n",
    "            logging.info(f\"{len(df)} instancias no guardadas\")\n",
    "\n",
    "# Función para analizar los sentimientos en el dataframe en chunks\n",
    "def analyze_sentiments_chunked(df, tokenizer, model, chunk_size=512, save_threshold=10000, process_chunk_size=5000):\n",
    "    processed_count = 0\n",
    "    ch_num = 0\n",
    "    # Procesar el dataframe en chunks de `process_chunk_size`\n",
    "    for start in range(0, len(df), process_chunk_size):\n",
    "        ch_num += 1\n",
    "        end = min(start + process_chunk_size, len(df))\n",
    "        chunk_df = df.iloc[start:end]\n",
    "\n",
    "        # defining lists for all sentiment labels and scores\n",
    "        sentiment_list = []\n",
    "        score_list = []\n",
    "        negative_scores = []\n",
    "        neutral_scores = []\n",
    "        positive_scores = []\n",
    "\n",
    "        logging.info(f\"Analyzing chunk n.{ch_num}\")\n",
    "        print(f\"Procesando chunk-group n.{ch_num}\")\n",
    "        \n",
    "        for idx, text in enumerate(chunk_df['text']):\n",
    "            chunks = list(chunk_text(text, tokenizer, chunk_size=chunk_size))\n",
    "            overall_sentiment = None\n",
    "            max_score = -1  # Inicializar a un valor bajo\n",
    "            neg_score, neu_score, pos_score = 0, 0, 0  # Initialize the score variables\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "                \n",
    "                # Realizar la inferencia en la GPU\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    logits = outputs.logits\n",
    "                    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "                \n",
    "                # Extract sentiment scores for each label\n",
    "                neg_score += probs[0][0].item()\n",
    "                neu_score += probs[0][1].item()\n",
    "                pos_score += probs[0][2].item()\n",
    "\n",
    "            # Normalizing the sentiment scores across chunks\n",
    "            num_chunks = len(chunks)\n",
    "            neg_score /= num_chunks\n",
    "            neu_score /= num_chunks\n",
    "            pos_score /= num_chunks\n",
    "\n",
    "            # Assign the label with the highest score\n",
    "            sentiment_scores = [neg_score, neu_score, pos_score]\n",
    "            overall_sentiment = ['Negative', 'Neutral', 'Positive'][sentiment_scores.index(max(sentiment_scores))]\n",
    "            \n",
    "            # Append the results\n",
    "            sentiment_list.append(overall_sentiment)\n",
    "            score_list.append(max(sentiment_scores))\n",
    "            negative_scores.append(neg_score)\n",
    "            neutral_scores.append(neu_score)\n",
    "            positive_scores.append(pos_score)\n",
    "        \n",
    "        # Asignar sentimientos y puntajes al chunk\n",
    "        df.loc[start:end-1, 'sentiment'] = sentiment_list\n",
    "        df.loc[start:end-1, 'max_score'] = score_list\n",
    "        df.loc[start:end-1, 'negative_score'] = negative_scores\n",
    "        df.loc[start:end-1, 'neutral_score'] = neutral_scores\n",
    "        df.loc[start:end-1, 'positive_score'] = positive_scores\n",
    "\n",
    "        processed_count += len(chunk_df)\n",
    "        \n",
    "        # Guardar el progreso después de cada `save_threshold` filas\n",
    "        if processed_count >= save_threshold:\n",
    "            guardar_progreso(df.iloc[start:end], ruta_guardado)\n",
    "            processed_count = 0\n",
    "    \n",
    "    # Guardar el progreso final\n",
    "    guardar_progreso(df, ruta_guardado)\n",
    "\n",
    "# Ruta para guardar el archivo de progreso\n",
    "ruta_guardado = r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\roBERTa results\\df_2nda_corrida_3sentiments.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:32:00,447 - INFO - Analyzing chunk n.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:32:54,508 - INFO - Analyzing chunk n.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:33:47,516 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:33:47,566 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:33:47,567 - INFO - Analyzing chunk n.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:34:39,873 - INFO - Analyzing chunk n.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:35:32,857 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:35:32,914 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:35:32,915 - INFO - Analyzing chunk n.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:36:26,212 - INFO - Analyzing chunk n.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:37:20,795 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:37:20,851 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:37:20,852 - INFO - Analyzing chunk n.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:38:18,418 - INFO - Analyzing chunk n.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:39:11,889 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:39:11,946 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:39:11,947 - INFO - Analyzing chunk n.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:40:05,220 - INFO - Analyzing chunk n.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:40:57,508 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:40:57,554 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:40:57,554 - INFO - Analyzing chunk n.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:41:49,910 - INFO - Analyzing chunk n.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:42:42,011 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:42:42,062 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:42:42,063 - INFO - Analyzing chunk n.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:43:34,361 - INFO - Analyzing chunk n.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:44:26,952 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:44:27,001 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:44:27,002 - INFO - Analyzing chunk n.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:45:19,889 - INFO - Analyzing chunk n.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:46:14,056 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:46:14,107 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 16:46:14,108 - INFO - Analyzing chunk n.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:46:56,564 - INFO - Guardando el progreso...\n",
      "2024-09-10 16:46:57,352 - INFO - Se han guardado 84045 instancias correctamente\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\Bipolar\\df_bipolar_full.csv\")\n",
    "df_run = analyze_sentiments_chunked(df, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>labels</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>max_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>positive_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It’s a bunch of conservatives looking for rede...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.882348</td>\n",
       "      <td>0.882348</td>\n",
       "      <td>0.108581</td>\n",
       "      <td>0.009071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best part of all this is the maga cult hat...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.912243</td>\n",
       "      <td>0.912243</td>\n",
       "      <td>0.082726</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They will grab onto anything to make trump int...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.863834</td>\n",
       "      <td>0.863834</td>\n",
       "      <td>0.121701</td>\n",
       "      <td>0.014466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got into an argument with a guy last night t...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.107158</td>\n",
       "      <td>0.003119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's amazing is that Trump's 34 felonies are...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.835902</td>\n",
       "      <td>0.835902</td>\n",
       "      <td>0.152027</td>\n",
       "      <td>0.012071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124040</th>\n",
       "      <td>&gt; No, Some Republicans aren’t motivated to vot...</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.482519</td>\n",
       "      <td>0.284823</td>\n",
       "      <td>0.482519</td>\n",
       "      <td>0.232658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124041</th>\n",
       "      <td>That would apply if Trump hadn’t won and lost....</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.593608</td>\n",
       "      <td>0.336064</td>\n",
       "      <td>0.593608</td>\n",
       "      <td>0.070328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124042</th>\n",
       "      <td>How many pardons has trump issued?</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.729522</td>\n",
       "      <td>0.210550</td>\n",
       "      <td>0.729522</td>\n",
       "      <td>0.059928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124043</th>\n",
       "      <td>Should post this all over the subs who keep bl...</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.776307</td>\n",
       "      <td>0.776307</td>\n",
       "      <td>0.209625</td>\n",
       "      <td>0.014067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124044</th>\n",
       "      <td>Kamala loves felons. Should be a great debate.</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.591324</td>\n",
       "      <td>0.081796</td>\n",
       "      <td>0.326879</td>\n",
       "      <td>0.591324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124045 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text submission_type  \\\n",
       "0       It’s a bunch of conservatives looking for rede...         comment   \n",
       "1       The best part of all this is the maga cult hat...         comment   \n",
       "2       They will grab onto anything to make trump int...         comment   \n",
       "3       I got into an argument with a guy last night t...         comment   \n",
       "4       What's amazing is that Trump's 34 felonies are...         comment   \n",
       "...                                                   ...             ...   \n",
       "124040  > No, Some Republicans aren’t motivated to vot...         comment   \n",
       "124041  That would apply if Trump hadn’t won and lost....         comment   \n",
       "124042                 How many pardons has trump issued?         comment   \n",
       "124043  Should post this all over the subs who keep bl...         comment   \n",
       "124044     Kamala loves felons. Should be a great debate.         comment   \n",
       "\n",
       "         subreddit      labels sentiment  max_score  negative_score  \\\n",
       "0         politics    Democrat  Negative   0.882348        0.882348   \n",
       "1         politics  Republican  Negative   0.912243        0.912243   \n",
       "2         politics  Republican  Negative   0.863834        0.863834   \n",
       "3         politics  Republican  Negative   0.889723        0.889723   \n",
       "4         politics  Republican  Negative   0.835902        0.835902   \n",
       "...            ...         ...       ...        ...             ...   \n",
       "124040  Republican  Republican   Neutral   0.482519        0.284823   \n",
       "124041  Republican  Republican   Neutral   0.593608        0.336064   \n",
       "124042  Republican  Republican   Neutral   0.729522        0.210550   \n",
       "124043  Republican    Democrat  Negative   0.776307        0.776307   \n",
       "124044  Republican    Democrat  Positive   0.591324        0.081796   \n",
       "\n",
       "        neutral_score  positive_score  \n",
       "0            0.108581        0.009071  \n",
       "1            0.082726        0.005031  \n",
       "2            0.121701        0.014466  \n",
       "3            0.107158        0.003119  \n",
       "4            0.152027        0.012071  \n",
       "...               ...             ...  \n",
       "124040       0.482519        0.232658  \n",
       "124041       0.593608        0.070328  \n",
       "124042       0.729522        0.059928  \n",
       "124043       0.209625        0.014067  \n",
       "124044       0.326879        0.591324  \n",
       "\n",
       "[124045 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_run = pd.read_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\roBERTa results\\df_2nda_corrida_3sentiments.csv\")\n",
    "df_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_run.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_run.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84045, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_run = df_run.drop_duplicates()\n",
    "df_run.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arreglando los duplicados y quitando columnas irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\34616\\miniconda3\\envs\\gpu_pluja\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "from transformers import RobertaForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Configuración para el uso de la GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Haciendo logging para monitorear errores\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    handlers=[logging.StreamHandler()])\n",
    "\n",
    "# Cargar el tokenizador y el modelo localmente en la GPU\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model.to(device)  # Mover el modelo a la GPU\n",
    "\n",
    "# Función para dividir el texto en chunks respetando el límite de tokens\n",
    "def chunk_text(text, tokenizer, chunk_size=512):\n",
    "    tokens = tokenizer(text, truncation=True, max_length=chunk_size, return_tensors='pt')\n",
    "    input_ids = tokens.input_ids[0]\n",
    "    for i in range(0, len(input_ids), chunk_size):\n",
    "        chunk_ids = input_ids[i:i + chunk_size]\n",
    "        yield tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
    "\n",
    "# Función para guardar el progreso en CSV\n",
    "def guardar_progreso(df, ruta_guardado):\n",
    "    if not df.empty:\n",
    "        try:\n",
    "            logging.info(\"Guardando el progreso...\")\n",
    "            arch_existe = os.path.isfile(ruta_guardado)\n",
    "            df.to_csv(ruta_guardado, mode='a', header=not arch_existe, index=False)\n",
    "            logging.info(f\"Se han guardado {len(df)} instancias correctamente\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ha habido un error al guardar el progreso: {e}\")\n",
    "            logging.info(f\"{len(df)} instancias no guardadas\")\n",
    "\n",
    "# Función para analizar los sentimientos en el dataframe en chunks\n",
    "def analyze_sentiments_chunked(df, tokenizer, model, chunk_size=512, save_threshold=10000, process_chunk_size=5000):\n",
    "    processed_count = 0\n",
    "    ch_num = 0\n",
    "    # Procesar el dataframe en chunks de `process_chunk_size`\n",
    "    for start in range(0, len(df), process_chunk_size):\n",
    "        ch_num += 1\n",
    "        end = min(start + process_chunk_size, len(df))\n",
    "        chunk_df = df.iloc[start:end]\n",
    "\n",
    "        # Definir listas\n",
    "        sentiment_list = []\n",
    "        negative_scores = []\n",
    "        neutral_scores = []\n",
    "        positive_scores = []\n",
    "\n",
    "        logging.info(f\"Analyzing chunk n.{ch_num}\")\n",
    "        print(f\"Procesando chunk-group n.{ch_num}\")\n",
    "\n",
    "        for idx, text in enumerate(chunk_df['text']):\n",
    "            chunks = list(chunk_text(text, tokenizer, chunk_size=chunk_size))\n",
    "            overall_sentiment = None\n",
    "\n",
    "            # Inicializar scores para cada chunk\n",
    "            negative_score_total = 0\n",
    "            neutral_score_total = 0\n",
    "            positive_score_total = 0\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "\n",
    "                # Realizar la inferencia en la GPU\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    logits = outputs.logits\n",
    "                    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "                # Sumar los scores de cada chunk\n",
    "                negative_score_total += probs[0][0].item()\n",
    "                neutral_score_total += probs[0][1].item()\n",
    "                positive_score_total += probs[0][2].item()\n",
    "\n",
    "            # Agregar los scores promediados\n",
    "            negative_scores.append(negative_score_total / len(chunks))\n",
    "            neutral_scores.append(neutral_score_total / len(chunks))\n",
    "            positive_scores.append(positive_score_total / len(chunks))\n",
    "\n",
    "            # Determinar el sentimiento principal\n",
    "            if max(negative_score_total, neutral_score_total, positive_score_total) == negative_score_total:\n",
    "                sentiment_list.append(\"Negative\")\n",
    "            elif max(negative_score_total, neutral_score_total, positive_score_total) == neutral_score_total:\n",
    "                sentiment_list.append(\"Neutral\")\n",
    "            else:\n",
    "                sentiment_list.append(\"Positive\")\n",
    "\n",
    "        # Asignar sentimientos y puntajes al chunk\n",
    "        df.loc[start:end-1, 'sentiment'] = sentiment_list\n",
    "        df.loc[start:end-1, 'negative_score'] = negative_scores\n",
    "        df.loc[start:end-1, 'neutral_score'] = neutral_scores\n",
    "        df.loc[start:end-1, 'positive_score'] = positive_scores\n",
    "        processed_count += len(chunk_df)\n",
    "\n",
    "        # Guardar el progreso después de cada `save_threshold` filas\n",
    "        if processed_count >= save_threshold:\n",
    "            \n",
    "            # Remover duplicados antes de guardar\n",
    "            df.drop_duplicates(inplace=True)\n",
    "            guardar_progreso(df.iloc[start:end], ruta_guardado)\n",
    "            processed_count = 0\n",
    "\n",
    "    # Guardar el progreso final y remover duplicados\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    guardar_progreso(df, ruta_guardado)\n",
    "\n",
    "# Ruta para guardar el archivo de progreso\n",
    "ruta_guardado = r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\roBERTa results\\df_3era_corrida_3sentiments.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:00:02,503 - INFO - Analyzing chunk n.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:00:56,521 - INFO - Analyzing chunk n.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:01:49,989 - INFO - Guardando el progreso...\n",
      "2024-09-10 17:01:50,038 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 17:01:50,041 - INFO - Analyzing chunk n.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:02:42,185 - INFO - Analyzing chunk n.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:03:34,837 - INFO - Guardando el progreso...\n",
      "2024-09-10 17:03:34,887 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 17:03:34,890 - INFO - Analyzing chunk n.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:04:27,357 - INFO - Analyzing chunk n.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:05:19,744 - INFO - Guardando el progreso...\n",
      "2024-09-10 17:05:19,789 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 17:05:19,791 - INFO - Analyzing chunk n.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:06:12,751 - INFO - Analyzing chunk n.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:07:05,635 - INFO - Guardando el progreso...\n",
      "2024-09-10 17:07:05,683 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 17:07:05,686 - INFO - Analyzing chunk n.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:07:58,413 - INFO - Analyzing chunk n.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:08:50,608 - INFO - Guardando el progreso...\n",
      "2024-09-10 17:08:50,649 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 17:08:50,651 - INFO - Analyzing chunk n.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:09:43,069 - INFO - Analyzing chunk n.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:10:35,027 - INFO - Guardando el progreso...\n",
      "2024-09-10 17:10:35,068 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 17:10:35,070 - INFO - Analyzing chunk n.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:11:28,128 - INFO - Analyzing chunk n.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:12:20,713 - INFO - Guardando el progreso...\n",
      "2024-09-10 17:12:20,762 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 17:12:20,765 - INFO - Analyzing chunk n.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:13:13,332 - INFO - Analyzing chunk n.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:14:06,301 - INFO - Guardando el progreso...\n",
      "2024-09-10 17:14:06,349 - INFO - Se han guardado 5000 instancias correctamente\n",
      "2024-09-10 17:14:06,351 - INFO - Analyzing chunk n.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando chunk-group n.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 17:14:48,169 - INFO - Guardando el progreso...\n",
      "2024-09-10 17:14:48,879 - INFO - Se han guardado 84045 instancias correctamente\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\Bipolar\\df_bipolar_full.csv\")\n",
    "analyze_sentiments_chunked(df, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>labels</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>positive_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It’s a bunch of conservatives looking for rede...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.882348</td>\n",
       "      <td>0.108581</td>\n",
       "      <td>0.009071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best part of all this is the maga cult hat...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.912243</td>\n",
       "      <td>0.082726</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They will grab onto anything to make trump int...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.863834</td>\n",
       "      <td>0.121701</td>\n",
       "      <td>0.014466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got into an argument with a guy last night t...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.107158</td>\n",
       "      <td>0.003119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's amazing is that Trump's 34 felonies are...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.835902</td>\n",
       "      <td>0.152027</td>\n",
       "      <td>0.012071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124040</th>\n",
       "      <td>&gt; No, Some Republicans aren’t motivated to vot...</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.284823</td>\n",
       "      <td>0.482519</td>\n",
       "      <td>0.232658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124041</th>\n",
       "      <td>That would apply if Trump hadn’t won and lost....</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.336064</td>\n",
       "      <td>0.593608</td>\n",
       "      <td>0.070328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124042</th>\n",
       "      <td>How many pardons has trump issued?</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.210550</td>\n",
       "      <td>0.729522</td>\n",
       "      <td>0.059928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124043</th>\n",
       "      <td>Should post this all over the subs who keep bl...</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.776307</td>\n",
       "      <td>0.209625</td>\n",
       "      <td>0.014067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124044</th>\n",
       "      <td>Kamala loves felons. Should be a great debate.</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.081796</td>\n",
       "      <td>0.326879</td>\n",
       "      <td>0.591324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124045 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text submission_type  \\\n",
       "0       It’s a bunch of conservatives looking for rede...         comment   \n",
       "1       The best part of all this is the maga cult hat...         comment   \n",
       "2       They will grab onto anything to make trump int...         comment   \n",
       "3       I got into an argument with a guy last night t...         comment   \n",
       "4       What's amazing is that Trump's 34 felonies are...         comment   \n",
       "...                                                   ...             ...   \n",
       "124040  > No, Some Republicans aren’t motivated to vot...         comment   \n",
       "124041  That would apply if Trump hadn’t won and lost....         comment   \n",
       "124042                 How many pardons has trump issued?         comment   \n",
       "124043  Should post this all over the subs who keep bl...         comment   \n",
       "124044     Kamala loves felons. Should be a great debate.         comment   \n",
       "\n",
       "         subreddit      labels sentiment  negative_score  neutral_score  \\\n",
       "0         politics    Democrat  Negative        0.882348       0.108581   \n",
       "1         politics  Republican  Negative        0.912243       0.082726   \n",
       "2         politics  Republican  Negative        0.863834       0.121701   \n",
       "3         politics  Republican  Negative        0.889723       0.107158   \n",
       "4         politics  Republican  Negative        0.835902       0.152027   \n",
       "...            ...         ...       ...             ...            ...   \n",
       "124040  Republican  Republican   Neutral        0.284823       0.482519   \n",
       "124041  Republican  Republican   Neutral        0.336064       0.593608   \n",
       "124042  Republican  Republican   Neutral        0.210550       0.729522   \n",
       "124043  Republican    Democrat  Negative        0.776307       0.209625   \n",
       "124044  Republican    Democrat  Positive        0.081796       0.326879   \n",
       "\n",
       "        positive_score  \n",
       "0             0.009071  \n",
       "1             0.005031  \n",
       "2             0.014466  \n",
       "3             0.003119  \n",
       "4             0.012071  \n",
       "...                ...  \n",
       "124040        0.232658  \n",
       "124041        0.070328  \n",
       "124042        0.059928  \n",
       "124043        0.014067  \n",
       "124044        0.591324  \n",
       "\n",
       "[124045 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\roBERTa results\\df_3era_corrida_3sentiments.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>labels</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>positive_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>It’s a bunch of conservatives looking for rede...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.882348</td>\n",
       "      <td>0.108581</td>\n",
       "      <td>0.009071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The best part of all this is the maga cult hat...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.912243</td>\n",
       "      <td>0.082726</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>They will grab onto anything to make trump int...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.863834</td>\n",
       "      <td>0.121701</td>\n",
       "      <td>0.014466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I got into an argument with a guy last night t...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.107158</td>\n",
       "      <td>0.003119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What's amazing is that Trump's 34 felonies are...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.835902</td>\n",
       "      <td>0.152027</td>\n",
       "      <td>0.012071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84040</th>\n",
       "      <td>124040</td>\n",
       "      <td>&gt; No, Some Republicans aren’t motivated to vot...</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.284823</td>\n",
       "      <td>0.482519</td>\n",
       "      <td>0.232658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84041</th>\n",
       "      <td>124041</td>\n",
       "      <td>That would apply if Trump hadn’t won and lost....</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.336064</td>\n",
       "      <td>0.593608</td>\n",
       "      <td>0.070328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84042</th>\n",
       "      <td>124042</td>\n",
       "      <td>How many pardons has trump issued?</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.210550</td>\n",
       "      <td>0.729522</td>\n",
       "      <td>0.059928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84043</th>\n",
       "      <td>124043</td>\n",
       "      <td>Should post this all over the subs who keep bl...</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.776307</td>\n",
       "      <td>0.209625</td>\n",
       "      <td>0.014067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84044</th>\n",
       "      <td>124044</td>\n",
       "      <td>Kamala loves felons. Should be a great debate.</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.081796</td>\n",
       "      <td>0.326879</td>\n",
       "      <td>0.591324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84045 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                               text  \\\n",
       "0           0  It’s a bunch of conservatives looking for rede...   \n",
       "1           1  The best part of all this is the maga cult hat...   \n",
       "2           2  They will grab onto anything to make trump int...   \n",
       "3           3  I got into an argument with a guy last night t...   \n",
       "4           4  What's amazing is that Trump's 34 felonies are...   \n",
       "...       ...                                                ...   \n",
       "84040  124040  > No, Some Republicans aren’t motivated to vot...   \n",
       "84041  124041  That would apply if Trump hadn’t won and lost....   \n",
       "84042  124042                 How many pardons has trump issued?   \n",
       "84043  124043  Should post this all over the subs who keep bl...   \n",
       "84044  124044     Kamala loves felons. Should be a great debate.   \n",
       "\n",
       "      submission_type   subreddit      labels sentiment  negative_score  \\\n",
       "0             comment    politics    Democrat  Negative        0.882348   \n",
       "1             comment    politics  Republican  Negative        0.912243   \n",
       "2             comment    politics  Republican  Negative        0.863834   \n",
       "3             comment    politics  Republican  Negative        0.889723   \n",
       "4             comment    politics  Republican  Negative        0.835902   \n",
       "...               ...         ...         ...       ...             ...   \n",
       "84040         comment  Republican  Republican   Neutral        0.284823   \n",
       "84041         comment  Republican  Republican   Neutral        0.336064   \n",
       "84042         comment  Republican  Republican   Neutral        0.210550   \n",
       "84043         comment  Republican    Democrat  Negative        0.776307   \n",
       "84044         comment  Republican    Democrat  Positive        0.081796   \n",
       "\n",
       "       neutral_score  positive_score  \n",
       "0           0.108581        0.009071  \n",
       "1           0.082726        0.005031  \n",
       "2           0.121701        0.014466  \n",
       "3           0.107158        0.003119  \n",
       "4           0.152027        0.012071  \n",
       "...              ...             ...  \n",
       "84040       0.482519        0.232658  \n",
       "84041       0.593608        0.070328  \n",
       "84042       0.729522        0.059928  \n",
       "84043       0.209625        0.014067  \n",
       "84044       0.326879        0.591324  \n",
       "\n",
       "[84045 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>positive_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It’s a bunch of conservatives looking for rede...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.882348</td>\n",
       "      <td>0.108581</td>\n",
       "      <td>0.009071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best part of all this is the maga cult hat...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.912243</td>\n",
       "      <td>0.082726</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They will grab onto anything to make trump int...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.863834</td>\n",
       "      <td>0.121701</td>\n",
       "      <td>0.014466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got into an argument with a guy last night t...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.107158</td>\n",
       "      <td>0.003119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's amazing is that Trump's 34 felonies are...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.835902</td>\n",
       "      <td>0.152027</td>\n",
       "      <td>0.012071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84040</th>\n",
       "      <td>&gt; No, Some Republicans aren’t motivated to vot...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.284823</td>\n",
       "      <td>0.482519</td>\n",
       "      <td>0.232658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84041</th>\n",
       "      <td>That would apply if Trump hadn’t won and lost....</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.336064</td>\n",
       "      <td>0.593608</td>\n",
       "      <td>0.070328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84042</th>\n",
       "      <td>How many pardons has trump issued?</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.210550</td>\n",
       "      <td>0.729522</td>\n",
       "      <td>0.059928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84043</th>\n",
       "      <td>Should post this all over the subs who keep bl...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.776307</td>\n",
       "      <td>0.209625</td>\n",
       "      <td>0.014067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84044</th>\n",
       "      <td>Kamala loves felons. Should be a great debate.</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.081796</td>\n",
       "      <td>0.326879</td>\n",
       "      <td>0.591324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84045 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text      labels  \\\n",
       "0      It’s a bunch of conservatives looking for rede...    Democrat   \n",
       "1      The best part of all this is the maga cult hat...  Republican   \n",
       "2      They will grab onto anything to make trump int...  Republican   \n",
       "3      I got into an argument with a guy last night t...  Republican   \n",
       "4      What's amazing is that Trump's 34 felonies are...  Republican   \n",
       "...                                                  ...         ...   \n",
       "84040  > No, Some Republicans aren’t motivated to vot...  Republican   \n",
       "84041  That would apply if Trump hadn’t won and lost....  Republican   \n",
       "84042                 How many pardons has trump issued?  Republican   \n",
       "84043  Should post this all over the subs who keep bl...    Democrat   \n",
       "84044     Kamala loves felons. Should be a great debate.    Democrat   \n",
       "\n",
       "      sentiment  negative_score  neutral_score  positive_score  \n",
       "0      Negative        0.882348       0.108581        0.009071  \n",
       "1      Negative        0.912243       0.082726        0.005031  \n",
       "2      Negative        0.863834       0.121701        0.014466  \n",
       "3      Negative        0.889723       0.107158        0.003119  \n",
       "4      Negative        0.835902       0.152027        0.012071  \n",
       "...         ...             ...            ...             ...  \n",
       "84040   Neutral        0.284823       0.482519        0.232658  \n",
       "84041   Neutral        0.336064       0.593608        0.070328  \n",
       "84042   Neutral        0.210550       0.729522        0.059928  \n",
       "84043  Negative        0.776307       0.209625        0.014067  \n",
       "84044  Positive        0.081796       0.326879        0.591324  \n",
       "\n",
       "[84045 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['index', 'submission_type', 'subreddit'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardado\n",
    "df.to_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\roBERTa results\\df_3era_corrida_3sentiments_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative    54468\n",
       "Neutral     25372\n",
       "Positive     4205\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Negative Score: 0.55\n",
      "Average Neutral Score: 0.36\n",
      "Average Positive Score: 0.09\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Negative Score: {round(df['negative_score'].mean(), 2)}\")\n",
    "print(f\"Average Neutral Score: {round(df['neutral_score'].mean(), 2)}\")\n",
    "print(f\"Average Positive Score: {round(df['positive_score'].mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Republicans vs Democrats analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democrats Sentiments: \n",
      "sentiment\n",
      "Negative    15459\n",
      "Neutral     10744\n",
      "Positive     2509\n",
      "Name: count, dtype: int64\n",
      "Republican Sentiments: \n",
      "sentiment\n",
      "Negative    39009\n",
      "Neutral     14628\n",
      "Positive     1696\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "democrats = df[df['labels'] == 'Democrat'] \n",
    "republicans = df[df['labels'] == 'Republican']\n",
    "\n",
    "print(\"Democrats Sentiments: \")\n",
    "print(democrats['sentiment'].value_counts())\n",
    "print(\"Republican Sentiments: \")\n",
    "print(republicans['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democrat Sentiments %\n",
      "Number of Democrat mentions: 28712 - (34.16% of total)\n",
      "Negative: 53.84%\n",
      "Neutral: 37.42%\n",
      "Positive: 8.74%\n"
     ]
    }
   ],
   "source": [
    "print(\"Democrat Sentiments %\")\n",
    "print(f\"Number of Democrat mentions: {len(democrats)} - ({round(len(democrats)/len(df)*100, 2)}% of total)\")\n",
    "print(f\"Negative: {round((democrats['sentiment'].value_counts()['Negative'] / len(democrats)*100), 2)}%\")\n",
    "print(f\"Neutral: {round(democrats['sentiment'].value_counts()['Neutral'] / len(democrats)*100, 2)}%\")\n",
    "print(f\"Positive: {round(democrats['sentiment'].value_counts()['Positive'] / len(democrats)*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Republican Sentiments %\n",
      "Number of Democrat mentions: 55333 - (65.84% of total)\n",
      "Negative: 70.5%\n",
      "Neutral: 26.44%\n",
      "Positive: 3.07%\n"
     ]
    }
   ],
   "source": [
    "print(\"Republican Sentiments %\")\n",
    "print(f\"Number of Democrat mentions: {len(republicans)} - ({round(len(republicans)/len(df)*100, 2)}% of total)\")\n",
    "print(f\"Negative: {round((republicans['sentiment'].value_counts()['Negative'] / len(republicans)*100), 2)}%\")\n",
    "print(f\"Neutral: {round(republicans['sentiment'].value_counts()['Neutral'] / len(republicans)*100, 2)}%\")\n",
    "print(f\"Positive: {round(republicans['sentiment'].value_counts()['Positive'] / len(republicans)*100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democrat Score Averages: \n",
      "Average Negative Score: 0.47\n",
      "Average Neutral Score: 0.39\n",
      "Average Positive Score: 0.13\n"
     ]
    }
   ],
   "source": [
    "print(\"Democrat Score Averages: \")\n",
    "print(f\"Average Negative Score: {round(democrats['negative_score'].mean(), 2)}\")\n",
    "print(f\"Average Neutral Score: {round(democrats['neutral_score'].mean(), 2)}\")\n",
    "print(f\"Average Positive Score: {round(democrats['positive_score'].mean(), 2)}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Republican Score Averages: \n",
      "Average Negative Score: 0.59\n",
      "Average Neutral Score: 0.34\n",
      "Average Positive Score: 0.07\n"
     ]
    }
   ],
   "source": [
    "print(\"Republican Score Averages: \")\n",
    "print(f\"Average Negative Score: {round(republicans['negative_score'].mean(), 2)}\")\n",
    "print(f\"Average Neutral Score: {round(republicans['neutral_score'].mean(), 2)}\")\n",
    "print(f\"Average Positive Score: {round(republicans['positive_score'].mean(), 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_Chiclanera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
