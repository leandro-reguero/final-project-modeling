{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "from transformers import pipeline\n",
                "from transformers import RobertaTokenizer\n",
                "\n",
                "import torch\n",
                "from torch.utils.data import Dataset\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "import gc\n",
                "import os\n",
                "\n",
                "from huggingface_hub import InferenceClient\n",
                "from transformers import AutoTokenizer\n",
                "import logging\n",
                "import time\n",
                "import requests\n",
                "from tqdm import tqdm\n",
                "import warnings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Index(['text', 'submission_type', 'subreddit', 'labels'], dtype='object')\n"
                    ]
                }
            ],
            "source": [
                "# Cargar el DataFrame con los comentarios de Reddit\n",
                "data = pd.read_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\Bipolar\\df_bipolar_lean - Copy.csv\")\n",
                "\n",
                "# Verifica que las columnas necesarias estén en el DataFrame\n",
                "print(data.columns)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>text</th>\n",
                            "      <th>submission_type</th>\n",
                            "      <th>subreddit</th>\n",
                            "      <th>labels</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>That’s the thing about Trump, he says things t...</td>\n",
                            "      <td>comment</td>\n",
                            "      <td>ModeratePolitics</td>\n",
                            "      <td>Republican</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>This isn't that deep. The audience is Christia...</td>\n",
                            "      <td>comment</td>\n",
                            "      <td>ModeratePolitics</td>\n",
                            "      <td>Republican</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Let's workshop the true meaning of this.\\n\\nFi...</td>\n",
                            "      <td>comment</td>\n",
                            "      <td>ModeratePolitics</td>\n",
                            "      <td>Republican</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>I have no time for Trump, his policies, or the...</td>\n",
                            "      <td>comment</td>\n",
                            "      <td>ModeratePolitics</td>\n",
                            "      <td>Republican</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>&gt; After repeating his usual unfounded claims a...</td>\n",
                            "      <td>comment</td>\n",
                            "      <td>ModeratePolitics</td>\n",
                            "      <td>Republican</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>28010</th>\n",
                            "      <td>&gt; No, Some Republicans aren’t motivated to vot...</td>\n",
                            "      <td>comment</td>\n",
                            "      <td>Republican</td>\n",
                            "      <td>Republican</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>28011</th>\n",
                            "      <td>That would apply if Trump hadn’t won and lost....</td>\n",
                            "      <td>comment</td>\n",
                            "      <td>Republican</td>\n",
                            "      <td>Republican</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>28012</th>\n",
                            "      <td>How many pardons has trump issued?</td>\n",
                            "      <td>comment</td>\n",
                            "      <td>Republican</td>\n",
                            "      <td>Republican</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>28013</th>\n",
                            "      <td>Should post this all over the subs who keep bl...</td>\n",
                            "      <td>comment</td>\n",
                            "      <td>Republican</td>\n",
                            "      <td>Democrat</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>28014</th>\n",
                            "      <td>Kamala loves felons. Should be a great debate.</td>\n",
                            "      <td>comment</td>\n",
                            "      <td>Republican</td>\n",
                            "      <td>Democrat</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>28015 rows × 4 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                    text submission_type  \\\n",
                            "0      That’s the thing about Trump, he says things t...         comment   \n",
                            "1      This isn't that deep. The audience is Christia...         comment   \n",
                            "2      Let's workshop the true meaning of this.\\n\\nFi...         comment   \n",
                            "3      I have no time for Trump, his policies, or the...         comment   \n",
                            "4      > After repeating his usual unfounded claims a...         comment   \n",
                            "...                                                  ...             ...   \n",
                            "28010  > No, Some Republicans aren’t motivated to vot...         comment   \n",
                            "28011  That would apply if Trump hadn’t won and lost....         comment   \n",
                            "28012                 How many pardons has trump issued?         comment   \n",
                            "28013  Should post this all over the subs who keep bl...         comment   \n",
                            "28014     Kamala loves felons. Should be a great debate.         comment   \n",
                            "\n",
                            "              subreddit      labels  \n",
                            "0      ModeratePolitics  Republican  \n",
                            "1      ModeratePolitics  Republican  \n",
                            "2      ModeratePolitics  Republican  \n",
                            "3      ModeratePolitics  Republican  \n",
                            "4      ModeratePolitics  Republican  \n",
                            "...                 ...         ...  \n",
                            "28010        Republican  Republican  \n",
                            "28011        Republican  Republican  \n",
                            "28012        Republican  Republican  \n",
                            "28013        Republican    Democrat  \n",
                            "28014        Republican    Democrat  \n",
                            "\n",
                            "[28015 rows x 4 columns]"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Autenticación con tu token de Hugging Face\n",
                "import os\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()\n",
                "client = InferenceClient(token=os.getenv('HF_CLIENT_TOKEN'))\n",
                "\n",
                "# Cargar el tokenizador\n",
                "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
                "\n",
                "# Función para dividir el texto en fragmentos, respetando el límite de tokens\n",
                "def chunk_text(text, tokenizer, chunk_size=512):\n",
                "    tokens = tokenizer(text, truncation=True, max_length=chunk_size, return_tensors='pt')\n",
                "    input_ids = tokens.input_ids[0]\n",
                "    for i in range(0, len(input_ids), chunk_size):\n",
                "        chunk_ids = input_ids[i:i + chunk_size]\n",
                "        yield tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
                "\n",
                "\n",
                "# Iniciando variables de backoff:\n",
                "initial_backoff = 5\n",
                "max_backoff = 300\n",
                "backoff_factor = 2\n",
                "def backoff_sleep(intento):\n",
                "    sleep_time = min(initial_backoff * (backoff_factor ** intento), max_backoff)\n",
                "    logging.info(f\"Rate limit hit. Sleeping for {sleep_time} seconds...\")\n",
                "    time.sleep(sleep_time)\n",
                "\n",
                "ruta_guardado = pd.read_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\Bipolar\\df_bipolar_lean - Copy.csv\")\n",
                "\n",
                "def guardar_progreso(df):\n",
                "    if not df.empty:\n",
                "        try:\n",
                "            logging.info(\"Guardando el progreso...\")\n",
                "            arch_existe = os.path.isfile(ruta_guardado)\n",
                "            # si el archivo existe, guardamos\n",
                "            df.to_csv(ruta_guardado, mode='a', header = not arch_existe, index=False)\n",
                "            logging.info(f\"Se han guardado {len(df)} instancias correctamente\")\n",
                "        \n",
                "        except Exception as e:\n",
                "            logging.error(f\"Ha habido un error al guardar el progreso: {e}\")\n",
                "            logging.info(f\"{len(df)} instancias no guardadas\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\Bipolar\\df_bipolar_lean - Copy.csv\")\n",
                "save_threshold = 1000\n",
                "records_collected = 0\n",
                "sentiment_list = []\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(28015, 4)"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Función para realizar el análisis de sentimientos en fragmentos\n",
                "columns = ['text', 'submission_type', 'subreddit', 'label', 'sentiment']\n",
                "df = pd.read_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\Bipolar\\df_bipolar_lean - Copy.csv\")\n",
                "\n",
                "\n",
                "def analyze_sentiments_chunked(texts, tokenizer, chunk_size=512, save_threshold = 10000, process_chunk_size = 5000):\n",
                "    intento = 0\n",
                "    sentiment_list = []\n",
                "    num_procesados = 0\n",
                "\n",
                "    for start in range(0, len(df), process_chunk_size):\n",
                "        end = min(start + process_chunk_size, len(df))\n",
                "        chunk_df = df.iloc[start:end]\n",
                "        chunk_sentiments = []\n",
                "        \n",
                "        for idx, text in enumerate(chunk_df['text']):\n",
                "            while True:\n",
                "                try: \n",
                "                    chunks = list(chunk_text(text, tokenizer, chunk_size=chunk_size))\n",
                "                    break # salir del loop si va guay\n",
                "\n",
                "                except requests.exceptions.HTTPError as e:\n",
                "                    if e.response.status_code == 429:\n",
                "                        backoff_sleep(intento)\n",
                "                        intento +=1\n",
                "                    else:\n",
                "                        logging.info('Oops, problema desconocido lol')\n",
                "                        break\n",
                "\n",
                "            for chunk in chunks:\n",
                "                response = client.text_classification(\n",
                "                model=\"cardiffnlp/twitter-roberta-base-sentiment\",\n",
                "                text=chunk\n",
                "                )\n",
                "\n",
                "\n",
                "            chunk_sentiments.append(response)\n",
                "        \n",
                "        # asignamos sentiment al chunk\n",
                "        chunk_df['sentiment'] = chunk_sentiments\n",
                "\n",
                "        # guardamos los sentiments en una lista grande\n",
                "        sentiment_list.extend(chunk_sentiments)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
                        "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
                        "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
                        "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
                    ]
                }
            ],
            "source": [
                "import logging\n",
                "import os\n",
                "import time\n",
                "import pandas as pd\n",
                "from huggingface_hub import InferenceClient\n",
                "from transformers import AutoTokenizer\n",
                "\n",
                "# haciendo logging para monitorear errores de rate-limit y retries\n",
                "logging.basicConfig(level=logging.INFO, \n",
                "                    format='%(asctime)s - %(levelname)s - %(message)s', \n",
                "                    handlers = [\n",
                "                        logging.StreamHandler(), \n",
                "                        logging.FileHandler(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\modelado\\bert_log_v1.log\", \n",
                "                                            mode= 'a')\n",
                "                                ]\n",
                "                    )\n",
                "\n",
                "# Autenticación con tu token de Hugging Face\n",
                "from dotenv import load_dotenv\n",
                "load_dotenv()\n",
                "\n",
                "client = InferenceClient(token=os.getenv('HF_CLIENT_TOKEN'))\n",
                "\n",
                "# Cargar el tokenizador\n",
                "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
                "\n",
                "# Function to split text into chunks respecting the token limit\n",
                "def chunk_text(text, tokenizer, chunk_size=512):\n",
                "    tokens = tokenizer(text, truncation=True, max_length=chunk_size, return_tensors='pt')\n",
                "    input_ids = tokens.input_ids[0]\n",
                "    for i in range(0, len(input_ids), chunk_size):\n",
                "        chunk_ids = input_ids[i:i + chunk_size]\n",
                "        yield tokenizer.decode(chunk_ids, skip_special_tokens=True)\n",
                "\n",
                "# Backoff variables\n",
                "initial_backoff = 5\n",
                "max_backoff = 300\n",
                "backoff_factor = 2\n",
                "\n",
                "def backoff_sleep(intento):\n",
                "    sleep_time = min(initial_backoff * (backoff_factor ** intento), max_backoff)\n",
                "    logging.info(f\"Rate limit hit. Sleeping for {sleep_time} seconds...\")\n",
                "    time.sleep(sleep_time)\n",
                "\n",
                "# Define save path\n",
                "ruta_guardado = r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\Scraping_results\\all_hotscrape_v2p10000_clean.csv\"\n",
                "\n",
                "# Function to save progress\n",
                "def guardar_progreso(df):\n",
                "    if not df.empty:\n",
                "        try:\n",
                "            logging.info(\"Guardando el progreso...\")\n",
                "            arch_existe = os.path.isfile(ruta_guardado)\n",
                "            # If the file exists, append without header; otherwise, write with header\n",
                "            df.to_csv(ruta_guardado, mode='a', header=not arch_existe, index=False)\n",
                "            logging.info(f\"Se han guardado {len(df)} instancias correctamente\")\n",
                "        \n",
                "        except Exception as e:\n",
                "            logging.error(f\"Ha habido un error al guardar el progreso: {e}\")\n",
                "            logging.info(f\"{len(df)} instancias no guardadas\")\n",
                "\n",
                "# Main function to analyze sentiments and save progress\n",
                "def analyze_sentiments_chunked(df, tokenizer, rate_limit_sleep, chunk_size=512, save_threshold=10000, process_chunk_size=1000):\n",
                "    intento = 0\n",
                "    processed_count = 0\n",
                "    ch_num = 0\n",
                "    # Process the dataframe in chunks of `process_chunk_size`\n",
                "    for start in range(0, len(df), process_chunk_size):\n",
                "        ch_num +=1        \n",
                "        end = min(start + process_chunk_size, len(df))\n",
                "        chunk_df = df.iloc[start:end]\n",
                "        sentiment_list = []\n",
                "        logging.info(f\"Analyzing chunk n.{ch_num}\")\n",
                "        print(f\"Procesando chunk-group n.{ch_num}\")\n",
                "        for idx, text in enumerate(chunk_df['text']):\n",
                "            while True:\n",
                "                try: \n",
                "                    chunks = list(chunk_text(text, tokenizer, chunk_size=chunk_size))\n",
                "                    break # Exit the loop if successful\n",
                "\n",
                "                except requests.exceptions.HTTPError as e:\n",
                "                    if e.response.status_code == 429:\n",
                "                        backoff_sleep(intento)\n",
                "                        intento += 1\n",
                "                    else:\n",
                "                        logging.info('Oops, problema desconocido lol')\n",
                "                        break\n",
                "\n",
                "            # Analyze sentiment for each chunk\n",
                "            overall_sentiment = None\n",
                "            max_score = -1  # Initialize to a value that any score will surpass\n",
                "\n",
                "            for chunk in chunks:\n",
                "                while True:\n",
                "                    try:\n",
                "                        response = client.text_classification(\n",
                "                            model=\"cardiffnlp/twitter-roberta-base-sentiment\",\n",
                "                            text=chunk\n",
                "                        )\n",
                "                        break\n",
                "\n",
                "                    except requests.exceptions.HTTPError as e:\n",
                "                        if e.response.status_code == 429:\n",
                "                            backoff_sleep(intento)\n",
                "                            intento +=1\n",
                "                        else:\n",
                "                            logging.info(f'Ha habido un problema inesperado: {e}')\n",
                "                            break\n",
                "\n",
                "                # Find the label with the highest score\n",
                "                for element in response:\n",
                "                    if element.score > max_score:\n",
                "                        max_score = element.score\n",
                "                        overall_sentiment = element.label\n",
                "\n",
                "            sentiment_list.append(overall_sentiment)\n",
                "\n",
                "            # sleep entre requests para evitar llegar al límite\n",
                "            time.sleep(rate_limit_sleep)\n",
                "\n",
                "\n",
                "        # Assign sentiments to the chunk\n",
                "        df.loc[start:end-1, 'sentiment'] = sentiment_list\n",
                "        \n",
                "        # Increment the processed count\n",
                "        processed_count += len(chunk_df)\n",
                "\n",
                "        # Save progress after every `save_threshold` rows\n",
                "        if processed_count >= save_threshold:\n",
                "            guardar_progreso(df.iloc[start:end])\n",
                "            processed_count = 0\n",
                "        \n",
                "\n",
                "\n",
                "    # Final save for any remaining data\n",
                "    guardar_progreso(df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-09-10 15:37:35,541 - INFO - Analyzing chunk n.1\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Procesando chunk-group n.1\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-09-10 15:37:36,015 - INFO - Rate limit hit. Sleeping for 5 seconds...\n",
                        "2024-09-10 15:37:41,131 - INFO - Rate limit hit. Sleeping for 10 seconds...\n",
                        "2024-09-10 15:37:51,245 - INFO - Rate limit hit. Sleeping for 20 seconds...\n",
                        "2024-09-10 15:38:11,378 - INFO - Rate limit hit. Sleeping for 40 seconds...\n"
                    ]
                }
            ],
            "source": [
                "df = pd.read_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\Bipolar\\df_bipolar_lean - Copy.csv\")\n",
                "df = df[:150]\n",
                "analyze_sentiments_chunked(df, tokenizer, rate_limit_sleep = 0.5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'df' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# cuando lo de arriba termine:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
                    ]
                }
            ],
            "source": [
                "# cuando lo de arriba termine:\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(5000, 5)"
                        ]
                    },
                    "execution_count": 39,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.shape"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.19"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
